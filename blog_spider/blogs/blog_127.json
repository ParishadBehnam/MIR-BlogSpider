{"type": "blog", "blog_name": "پایتونیستـــ", "blog_url": "http://pythonist.blog.ir/", "post_url_1": "http://pythonist.blog.ir/post/what_is_machine_learning_and_learning", "post_title_1": "یادگیری و یادگیری ماشین", "post_content_1": "یادگیری ماشین به معنای یادگیری ماشین از روی داده­ ها است.یادگیری چه چیزی؟..\nاین که ماشین چه چیزی را از داده­ ها می ­آموزد تنها به دسته بندی ماشین­های دارای قدرت یادگیری کمک می­کند. من در  این بخش نمی­ خواهم درباره­ ی این موضوع صحبت کنم. در این جا تنها و تنها می خواهم کمی درباره­ ی مفهوم یادگیری بحث کنم.\nیادگیری در ماشین و یادگیری در انسان دو مقوله ­ی بسیار شبیه به هم هستند. این شباهت اتفاقی نیست. دلیل این شباهت آن است که کسانی که مفاهیم یادگیری ماشین را پایه گذاری کرده­ اند خود انسان بوده ­اند و همواره نیم ­نگاهی به آن چه در درون انسان می­ گذرد داشته­ اند البته بعضی به صورت خودآگاه و بعضی به صورت ناخودآگاه. بنا براین، ما در این بخش، انسان و نیز ماشین یادگیرنده را عامل یادگیرنده (learning agent)  می ­نامیم.\nیادگیری، کلیت­ بخشی و خودمختاری\nیادگیری (learning) و کلیت ­بخشی (generalization) دو مفهوم کاملا به هم نزدیک و تقریبا دو نام متفاوت برای یک چیز اند. در گام اول وقتی عامل یادگیرنده با انبوهی از داده­ ها مواجه می­شود ابتدا به دنبال داده ­های مفید برای یادگیری می­گردد. مثلا انسان همواره با انبوهی از داده ­های ورودی از طریق حواس پنج گانه درگیر است. حتی ذخیره­ ی­ این داده ها برای رایانه ­های بسیار بزرگ غیر ممکن است. بنا براین مغز انسان در میان این انبوه داده ­ها همواره به دنبال داده ­های مفید است. مفید برای چه؟ مفید برای هدف یا اهدافی که در آن لحظه برای رسیدن به آن در تلاش است. البته این فرآیند بسیار پیچیده و مهم، هنوز به طور قابل قبولی در ماشین ­ها پیاده سازی نشده و طراح ماشین قبل از به کار گیری ماشین ساعت ها بر روی انتخاب و پالایش داده ­ها فکر و برنامه ­ریزی می ­کند. هرچند  با معرفی مکانیزم توجه (attention) ،گام هایی بسیار کوچک در این راه برداشته شده است.\nپس از این که عامل یادگیرنده داده­ های خود را دریافت کرد درگام دوم سعی می­ کند آن را درون خود بازنمایی (represent) کند. در این جا هم از  دست ماشین کار زیادی بر نمی­ آید و باز این طراح ماشین است که شیوه­ ی بازنمایی داده­ ها را مشخص می­کند. مثلا طراح ماشین ممکن است برای بازنمایی کلمات یک متن یکی از دو روش زیر را انتخاب کند:\n1- استخراج لیست کلمات منحصر به فرد درون متن و انتساب اعداد منحصر به فرد به آن ها و تبدیل متن به رشته ای از اعداد\n2-استخراج لیست کلمات منحصر به فرد درون متن و انتساب اعداد منحصر به فرد به آن ها و تبدیل متن به بردار وان هات (one-hot vector)\n\n\n\nماشین های یادگیرنده در گام سوم خودنمایی بیشتری دارند. یک ماشین یادگیرنده پس از آن که داده ­ها را دریافت و در درون خود بازنمایی کرد به دنبال کشف قواعد کلی از روی داده­ ها است. طیف وسیع الگوریتم­های یادگیری ماشین عمدتا در این گام قرار می­گیرند.**ذکر یک مثال ساده**\nدر همین جا می توان یک تعریف ساده از یادگیری عمیق ارائه کرد. یادگیری عمیق یعنی توانایی بیشتر در کلیت بخشی و کشف قواعد کلی ­تر یا به عبارتی کشف قاعده­ ی قاعده ­ها. یک عامل یادگیرنده می­تواند به قواعدی که از داده ­ها و رابطه ­ی بین آن ها کشف کرده­ است مجددا فکر کند و قواعد سطح بالاتری استقرا کند. جالب است که ما در زندگی روزمره به افرادی که قواعد کلی­ تری از علوم را می­دانند یا به عبارتی اشراف بیشتری بر علوم دارند صفت دارای بینش عمیق را نسبت می­دهیم. \nدر مقابل یادگیری عمیق آن یادگیری سطحی (shallow) قرار دارد. تصور کنید دانشجویی را که درس معادلات دیفرانسیل را با به هم پیوستن مشتی خرده تئوری می ­آموزد که تنها برای حل سؤالات امتحانی مفید است و دانشجویی که تمام اثبات ها و چرایی های روش های حل در معادلات دیفرانسیل را میداند. قطعا دومی بینش عمیق­ تری نسبت به موضوع دارد. \nپس جا دارد که ما یادگیری بهتر را یادگیری عمیق ­تر بنامیم ؛ یادگیری ­ای که حاصل آن عبارات جهان شمول تر و اتکاپذیر­تر است و باعث می­ شود که عامل یادگیرنده خود را بهتر با محیط جدید سازگار (adopt) کند.  این سازگاری ناشی از آن است که عامل نیازی به یک جدول به شکل اگر-آن­گاه برای اعمال خود ندارد و می­تواند  (action) عملدرست را بر اساس قواعد کلی که آموخته استتنتاج پیداکند. به عبارت دیگر عمق زیاد دانش عامل یادگیرنده باعث می­شود که طراح عامل در مورد ناشناخته­ بودن فضای جدید و ادراکات جدید نگرانی­ کم تری داشته باشد. یعنی طراح عامل نیاز کم­تری به کسب اطلاعات از محیط به کارگیری عامل خواهد داشت. تصور کنید که دو ماشین یادگیرنده با انبوهی از عملیات جمع و ضرب بین اعداد متفاوت مواجه هستند. ماشین اول تنها آن­ها را حفظ می­کند. اما ماشین دوم میتواند روابط بین آن ها را کشف کند. طبیعی است طراح ماشین اول همواره نگران است که در محیط عمل، ورودی محاسباتی جدید و قبلا دیده نشده به ماشین داده نشود. اما طراح ماشین دوم از این بابت خیالش راحت تر است.\nOverfit  Underfit\nعامل یادگیرنده اگر بتواند فرآیند کلیت بخشی را بر اساس داده های ورودی به خوبی انجام دهد آن گاه یک عامل مفید و قابل استفاده است. اما سوال این جا است که چه روشی برای فهم این موضوع وجود دارد؟ چگونه می توان اطمینان پیدا کرد که عامل یادگیرنده کار خود را به خوبی انجام داده است؟ \nبرای این کار کافی است بخشی از داده ها را ازعامل مخفی نگه داریم اگر عامل بتواند حتی بر روی داده های دیده نشده (unseen) هم به طرزمطلوبی عمل کند نشان می دهد که عامل، مفید و قابل استفاده است. اما اگر عامل بر روی داده های دیده شده به خوبی عمل کند  و روی داده های دیده نشده بد عمل کند نشان از این دارد که عامل نتوانسته قواعد کلی را از روی داده های دیده شده استنتاج کند و احتمالا آن ها را تنها در درون خود ذخیره کرده است. یا این که آن مقدار که باید دید عمیقی نسبت به داده ها و رابطه ی بین آنها پیدا نکرده است. چنین رویدادی اصطلاحا overfit نامگذاری میشود.\nاما یک حالت بد تر نیز وجود دارد و آن حالتی است که ماشین حتی بر روی داده های دیده شده هم به خوبی عمل نمی کند. این رخداد عمدتا به دلیل کم بودن حجم داده ی دیده شده است یا به دلیل ضعف ماشین.\nدر ادبیات متداول یادگیری ماشین داده ی دیده شده را داده ی آموزش (train) و داده ی دیده نشده را داده ی آزمون (test) مینامند.\n\nپس...\nبه طور کلی هر چه ساختار عامل یادگیرنده مستقل از محیط به کارگیری آن باشد یعنی طراح عامل به اطلاعات کم تری از محیط به کارگیری عامل احتیاج داشته باشد آن عامل خودمختاری (autonomy) بیشتری دارد. خود مختاری نقش اساسی در هوشمندی یک عامل را دارد. در این جا شما را به توجه بین مفهوم خودکار بودن و خودمختار بودن جلب می­کنم. در این جامشاهده می­ شود که دستگاه­های خودکار که در ادبیات فارسی روزمره به اشتباه هوشمند نامیده می­شوند اصلا هوشمند نیستند. یا به عبارت محترمانه ­تر از حداقل هوشمندی برخورداراند. از این دیدگاه \"کارت هوشمند سوخت\" یک نام گذاری نادرست است.", "post_url_2": "http://pythonist.blog.ir/post/%D8%AF%D8%A7%D9%86%D9%84%D9%88%D8%AF-%DA%A9%D8%AA%D8%A7%D8%A8-%DA%AF%D9%81%D8%AA-%D9%88-%D8%B4%D9%86%D9%88%D8%AF%D9%87%D8%A7%DB%8C%DB%8C-%D8%AF%D8%B1%D8%B1%DB%8C%D8%A7%D8%B6%DB%8C%D8%A7%D8%AA", "post_title_2": "دانلود کتاب گفت و شنودهایی در ریاضیات", "post_content_2": "ما بچه هامونم دارن مادر و پدر میشن میشن ولی هنوز نفهمیدیم انتگرال رو برای چی خوندیم! این جمله طنز آمیز حکایت وضعیت آموزش و به خصوص آموزش ریاضی در کشور ما است. خیلی کم پیش میاد که معلم یا استاد در مورد چرایی مباحث اون جلسه صحبتی بکنه. خیلی کم پیش میاد که در ابتدا، دانش آموز و دانشجو تشنه ی مطلبی بشن و بعد مطلب بهشون ارایه بشه. انسان هم که تا تشنه نشه، چیزی رو دنبال نمی کنه. و مطلب جالب تر در مورد علم اینه که حتی اگر دقیقا همون کارای وقت تشنگی رو انجام بده باز هم خبری فهم عمیق نیست. انگار مغز فقط در حالت تشنگیه که آموزش میبینه. در چنین حالتی تنها تشنگی نمره است که باقی میمونه. پس کاملا طبیعیه که تشنگان نمره در صدر نخبگان جامعه قرار بگیرند. عده ی قلیلی هم که تونستند به صورت خودجوش، در خودشون تشنگی ایجاد کنن این قدر جلو میفتن که مدیران سیراب! از آموزش و پژوهش حالشونو به هم میزنن. بگذریم...\nدر این وضعیت به هم ریخته، قصه آموزش ریاضی هم مستثنی نشده و ما همیشه پیش از اون (و حتی پس از اون)که فرمول ها رو ذهنمون انبار کنیم از فهمیدن چرایی آموزش اون بحث محروم بودیم. هیچ وقت تلخی این جمله از استاد معادلات دیفرانسیلم یادم نمیره که گفت \"شما که مهندس هستید و نیازی به اثبات فرمول ها نیست!\". این شاید جزو ده لحظه ی تلخ عمرم تا به امروز باشه. به هرحال کتابی که می خوام معرفی کنم برای اونایی هست که میخوان توی ریاضی سیر و سلوک کنن و به ریاضی به عنوان یک رویکرد نگاه کنن نه به عنوان یه ابزار. توضیح بیشتری نمیدم و دعوت می کنم کتاب رو یه نفس بخونید. کتاب کم حجم در قالب سه داستان که همه یک مطلب رو بیان می کنن. امیدوارم از خوندن کتاب لذت ببرید. خواهش می کنم اگر کتابی مثل این سراغ دارید به من معرفی کنید.\nسپاس\n\n\n\n\n\nلینک دانلود\n", "post_url_3": "http://pythonist.blog.ir/post/tensorflow-intro", "post_title_3": "آغاز کار با تنسورفلو", "post_content_3": "مساله ای که معمولا در استفاده از تنسورفلو و حتی تیانو وجود دارد این است که ما نمی دانیم این دو دقیقا دقیقا چه هستند! مساله ای که معمولا مارا مجبور به استفاده ار ابزارهای سطح بالاتر مثل کراس می کند. این کتابخانه ها خودشان را به عنوان ابزارهایی برای پیاده سازی الگوریتم های یادگیری عمیق معرفی کردند. اما درواقع مفاهیم پشت صحنه این دو ابزار مفاهیمی مستقل از یادگیری عمیق است. مفهومی که در عین سادگی پیچیده ترین ساختارهای محاسباتی را برای ما تولید می کند. گراف محاسباتی۱ مفهوم پایه برای این دو ابزار قدرتمند است. گراف محاسباتی شبیه درخت های پیشوندی و پسوندی(برای عملیات ریاضی) است با این تفاوت که الزاما ساختار به صورت درخت نیست. مثلا عبارت های زیر در نظر بگیرید:\nc = a + bd = b + 1e = c * d\n\nگراف محاسباتی برای این عبارات به شکل زیر است:\n\n\nاگر مقدار a برابر ۲ و مقدار b برابر ۱ باشد گراف محاسباتی به صورت زیر در می آید که مقدار عبارت نهایی برابر ۶ می شود.\n\nتمام اجزای این گراف برای تنسورفلو به طور کامل قابل بیان است. تا جایی که می تواند عملیات بهینه سازی مبتنی بر مشتق (مثل گرادیان نزولی) را بر روی یک گراف انجام دهد. به طور کلی مشتق گیری برروی گراف های محاسباتی از قوانین ساده ای پیروی می کند. برای شکل بالا اعمال این قواعد به شکل زیر خواهد شد:\n\nدر شکل زیر هم مسیر مشتق گیری بر روی گراف محاسباتی نشان داده شده است:\n\n\nبه طور کلی دو قانون ساده برای مشتق گیری بر روی گراف محاسباتی وجود دارد. \n۱- مشتق های موازی با هم جمع میشوند\n۲- مشتق های سری در هم ضرب می شوند.\nمثلا در شکل زیر:\n\n\nمشتق به صورت زیر در می آید:\n\n\nادامه مطلب", "post_url_4": "http://pythonist.blog.ir/post/recommender-systems", "post_title_4": "سیستم های توصیه گر", "post_content_4": "سیستم های توصیه گر (Recommender Systems) سیستم های نرم افزاری هستند که سعی می کنند آیتم های مناسب و محبوب یک کاربر را از میان انبوهی از گزینه ها کشف کننند و به او پیشنهاد بدهند.علایق کاربر و ویژگی آیتم ها دو منبع اصلی توصیه گری هستند. معمولا در سیستم های توصیه کننده به این منبع اطلاعاتی اکتفا میشود اما در برخی موارد اطلاعات پیرامونی نیز مد نظر طراحان سیستم قرار می گیرد که در همین پست و در بخش زمینه به آن پرداخته شده است.\n\n\nادامه مطلب", "post_url_5": "http://pythonist.blog.ir/post/what-is-conditional-random-field-2", "post_title_5": "میدان تصادفی شرطی چیست؟ قسمت دوم", "post_content_5": "میدان تصادفی\nباید بفهمیم که یک میدان تصادفی شرطی چگونه به جهان نگاه می کند. وقایع اطراف خود را چگونه می فهمد و بازنمایی می کند. شاید بررسی مفاهیمی که در این مدل خاص مخفی شده است به فهم این موضوع کمک کند.\nمیدان\nدر ریاضیات دو نوع میدان وجود دارد. میدان جبری و میدان برداری. میدان جبری با مفهومی از میدان که در فیزیک دوران دبیرستان دیده ایم کاملا متفاوت است. اما میدان برداری تقریبا همان مفهوم آشنا است. میدان برداری عبارت است از فضایی که به هر نقطه ی آن بردار نسبت داده شده است. ما در این جا دقیقا با همین مفهوم یعنی مفهوم میدان برداری کار داریم. با این تفاوت که ما این جا یک فضای احتمالی داریم.\n\n\n\nفضای احتمالی\nفضای احتمالی از دو عنصر تشکیل شده است. عنصر اول فضای نمونه است. فضای نمونه عبارت است از مجموعه تمام اتفاقاتی که ممکن است در جهان مد نظر ما رخ بدهد. مثلا در دنیای بازی تاس تنها 6 اتفاق ممکن است بیفتد.\nعنصر دوم تابعی است که به ازای هر زیر مجموعه از فضای نمونه ای یک عدد تولید می کند. این عدد بین صفر و یک است که همان احتمال رخداد یک زیر مجموعه مفروض است.\nمیدان تصادفی\nوقتی ما به یک میدان برداری به شکل غیر قطعی نگاه کنیم آن میدان برداری تبدیل به یک میدان تصادفی می شود. به همین راحتی. مثلا در فضای R3  احتمال رخداد یک بردار برابر صفر است! خوب این مطلب واضحی است که  تقسیم هر عدد متناهی بر هر عدد نامتناهی صفر است. اما وقتی در فضای گسسته به بررسی احتمال می پردازیم موضوع کاملا فرق می کند چون دیگر فضای نمونه ای نامنتناهی نیست و محدود به مقادیری خاص است. مثلا در یک برچسب گذاری دنباله ای (sequence labeling) در حوزه ی پردازش زبان طبیعی، قطعا تنوع کلمات قبل و بعد کلمه جاری محدود به دامنه ی خاصی است. پس می توان با شمارش، احتمال آن ها را حساب کرد.\nکاملا درست حدس زدید. این بردار ها همان بردار های ویژگی هستند که در یادگیری ماشین همواره به دنبال بهترین هایشان هستیم. و این جا هم از این قاعده مستثنا نیست. در این جا هم مثل یادگیری ماشین تصفیه داده ها و پیدا کردن بردار ویژگی مناسب حل مساله را تشکیل می دهد و الا آموزش(train) مدل که از همه بر می آید!\n\nادامه دارد...\n"}